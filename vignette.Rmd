---
title: Using multiple imputation to improve the harmonization of repeated cross-national
  surveys
author: "Philippe Joly, BGSS, Humboldt-Universität zu Berlin"
date: "March 2018"
output:
  html_document:
    includes:
      before_body: doc_prefix.html
  pdf_document: default
bibliography: ref.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
---

![&nbsp;](ccby.png)

**This vignette was prepared as part of the [Fellowship Freies Wissen](https://wikimedia.de/wiki/BildungWissenschaftKultur/Fellowprogramm) sponsored by Wikimedia Deutschland, the Stifterverband, and the VolkswagenStiftung. The content is under a [CC BY 4.0 license](https://creativecommons.org/licenses/by/4.0/). The vignette was writen in R markdown and the original script is available on my [GitHub page](https://github.com/jolyphil/mi-survey-harmonization). Comments and pull requests are welcome.**

**[R markdown](https://rmarkdown.rstudio.com/) documents are a form of [literate programming](https://en.wikipedia.org/wiki/Literate_programming). By weaving natural language and code together in a single text file, literate programming makes research more transparent and reproducible. It is also a nice tool for the development of [Open educational resources (OER)](https://en.wikipedia.org/wiki/Open_educational_resources).**

---

# Missing data in repeated cross-national surveys 

Missing data is a ubiquitous problem when analyzing cross-national social and political surveys. Data is said to be "sporadically missing" when respondents cannot or decline to answer certain questions [@resche-rigon_multiple_2016]. With repeated cross-national surveys, another concern is that questionnaires might change over time. In new survey waves, some questions might be introduced; other might be rephrased or discontinued. Data is then "systematically missing" in some country-waves [@resche-rigon_multiple_2016]. This makes it particularly challenging for scholars to track the evolution of beliefs, attitudes, and behavior within certain populations over time. 

Since the 1980s, there has been a rapid increase in the number of international social and political surveys. Large projects such as the [European Social Survey (ESS)](http://www.europeansocialsurvey.org/), the [International Social Survey Programme (ISSP)](http://www.issp.org/), the [European Values Study (EVS)](http://www.europeanvaluesstudy.eu/), and the [World Values Survey (WVS)](http://www.worldvaluessurvey.org/) have together collected responses from hundreds of thousands of respondents in the last thirty years. Some research teams have now taken on the task of harmonizing this data [see @neundorf_global_2017; @slomczynski_survey_2017]. 

In order to perform longitudinal analyses with repeated cross-national surveys, scholars have typically coped with the problem of systematically missing data by relying on listwise deletion, therefore ignoring all observations with missing data, or by using informed guesses to fill in the missing observations. Both solutions have their disadvantages. Listwise deletion is inefficient as it forces the investigator to discard valuable information. It can also introduce biases if the observations are not "missing completely at random" (MCAR) [@rubin_multiple_1987]. The "guessing" strategy, whether it is based on theoretical assumptions or empirical estimations (e.g. mean imputation), underestimates the uncertainty of the guesses. Analyzing this data will produce artificially low standard errors [for a good review of the topic, see @king_analyzing_2001].

**How can we improve the harmonization of repeated cross-national surveys?**

In this vignette, I would like to demonstrate a technique I have been using in my dissertation to handle this type of problem: multiple imputation (MI). I build on a long tradition in survey research showing that MI is usually a more efficient and less biased way to handle missing data than listwise deletion and single imputation methods. MI has been considered an appropritate solution to account for mismatches across survey questionnaires. While MI uses the entire sample (and therefore does not discard valuable data), it also preserves _uncertainties_ of the imputation process [@caren_social_2011; @king_analyzing_2001]. I present a typical case of systematically missing data in repeated cross-national surveys and illustrate how I would go around it by performing the analysis with MI data in R. The `mice` package performs multiple imputation using fully conditional specification (FCS) [@van_buuren_mice:_2011].

# A demonstration with the R mice package and data from the European Values Study

The European Values Study (EVS) is a large multinational survey project examining European citizens' ideas and behavior with regards to "life, family, work, religion, politics and society" [@evs_about_2017]. So far, four EVS waves have been published (the fifth wave is ongoing): 1) in 1981-1984, 2) in 1990-1993, 3) in 1999-2001, and 4) in 2008-2010. 

One problem when analyzing EVS longitudinal data is that the way the education of respondents is measured changed over the course of the study. In the first two waves, the EVS only asked respondents at what age they completed their formal education. In the subsequent waves, it also asked respondents what was their highest level of education. Most social scientists recognize that the level of education is a better indicator of socio-economic status. If we want to use this variable in our analyses, we either have to discard the first two waves or impute the missing values. 

Let's first have a look at a subset of the EVS data. You can download the EVS Longitudinal datafile, 1981-2008 (ZA4804 Data file, Version 3.0.0) from the [GESIS website](https://dbk.gesis.org/dbksearch/SDesc2.asp?ll=10&notabs=&af=&nf=&search=&search2=&db=E&no=4804) and save it in your working directory. In this example, I use the .dta (Stata) file. 

## Data preparation

In R, we start by loading the packages necessary for this demonstration (if needed, install them with the function `install.packages()`). 

```{r load_packages, message = FALSE}
library(dplyr) # used for data wrangling
library(ggplot2) # used for data visualization
library(haven) # used to import Stata and SPSS files
library(lme4) # performs linear mixed-effects models
library(magrittr) # allows pipe operator
library(mice) # performs MI
```

After, we load a subset the EVS dataset in the R working environment. The `read_dta()` function from the `haven` package allows to import .dta files in R. 

```{r filepath}
#_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
# Set path to EVS data
datapath <- "ZA4804_v3-0-0.dta"
```

```{r select_path, include=FALSE}

#_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
# For my own computers... adapt or delete this part if you need to.

pathtofile <- c("C:/Users/jolyphil/Documents/Data/article1/data/raw/EVS_longitudinal/ZA4804_v3-0-0.dta", 
              "/media/philippe/Fichiers/Data/ZA4804_v3-0-0.dta",
              "E:/Data/ZA4804_v3-0-0.dta")
datapath <- pathtofile[3]
```

```{r load_data}

#_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
# Load a subset of variables
evs <- datapath %>%
  
  # Convert Stata datafile to R dataframe
  read_dta %>%
  
  # Keep only a subset of variables
  select(S002EVS, S003A, S024, A170, X001, X003, X023, X025R) %>%
  
  # Rename variables
  rename(wave = S002EVS, country = S003A, countrywave = S024, 
         stflife = A170, women = X001, age = X003, 
         eduage = X023, edulvl = X025R)
```

Suppose we would like to estimate the effect of the level of education on life satisfaction. We could select a few variables to work with:

* `wave`: the EVS wave (1 to 4)
* `country`: a country id
* `countrywave`: a country-wave id
* `stflife`: the question asks "how satisfied are you with your life as a whole these days?" and answers go from (1) "Dissatisfied" to (10) "Satisfied"
* `women`: gender
* `age`: age
* `eduage`: age at which respondents completed their formal education
* `edulvl`: highest level of education attained by respondents; three levels: 1) low (primary), 2) middle (secondary), and 3) high (tertiary). 

Note that you could use other variables if you would like to. For a list of available variables in the EVS Longitudinal Data Files, you can have a look [here](https://dbk.gesis.org/EVS/Variables/compview.asp?db=QEVSLF&id=&add=ZA4804&var=&lang=&id2=&var2=&lang2=&vsearch=&vsearch2=&s1=1&s2=1&s3=1&bool=).

I reduce the sample to respondents of countries which were part of all four EVS waves. 

```{r reduce_sample}
evs <- evs %>% 
  
  # Group by country and wave
  group_by(country, wave) %>%
  
  # Aggregate and tag each wave with value "1" in new variable 'tag_wave'
  summarize(tag_wave = 1) %>% 
  
  # Group again; now, only by country
  group_by(country) %>%
  
  # Aggregate, 
  # sum up the tags to count the number of waves per country, and
  # create var 'keep' taking value T if sum of waves per country is 4
  summarize(keep = sum(tag_wave) == 4) %>%
  
  # Merge the aggregate dataframe with the original individual-level data
  merge(evs) %>%
  
  # Filter countries with 4 waves
  filter(keep == T) %>%
  
  # Drop variable 'keep'
  select(-one_of("keep"))
```

Finally, We can also change the class of a few variables, from `labelled` to `factor`. Variables were automatically classified as `labelled` when we imported the .dta file, however this format is not supported well by some R functions.

```{r recode_factors}
evs <- evs %>% 
  mutate(country = droplevels(as_factor(country)),
         wave = droplevels(as_factor(wave)),
         countrywave = droplevels(as_factor(countrywave)),
         stflife = droplevels(as_factor(stflife)),
         women = droplevels(as_factor(women)),
         edulvl = droplevels(as_factor(edulvl)))
```

```{r define_N, echo=FALSE}
N_obs <- as.integer(count(evs))
N_countries <- evs %>% 
  group_by(country) %>% 
  summarize(tag_country = 1) %>% 
  summarize(sum(tag_country)) %>%
  as.integer
```

We now have `r N_obs` respondents from `r N_countries` countries (including West Germany and Northern Ireland as "countries").

```{r print_freqtable}
table(evs$country, evs$wave)
```

## Missing patterns

We can start investigating patterns of missingness in the data using the function `md.pattern()` from the `mice` package.

```{r print_misstable}
misstable <- md.pattern(evs)
# exclude columns for country, wave, countrywave: zero missing.
misstable[, 4:ncol(misstable)]
```

```{r save_misstable_values, echo=FALSE}
misstable <- md.pattern(evs)
miss_total <- misstable[nrow(misstable), ncol(misstable)] %>% as.integer
miss_edulvl <- misstable[nrow(misstable), "edulvl"] %>% as.integer
miss_zero <- row.names(misstable)[1] %>% as.integer
miss_edulvl_only <- row.names(misstable)[6] %>% as.integer
```

The table above combines both sporadically and systematically missing data. We can see that `r miss_zero` observations have no missing values. Out of all `r miss_total` missing values, `r miss_edulvl` values are missing for the variable `edulvl`. `r miss_edulvl_only` observations have a missing value _only_ for this variable. 

The code below produces a new aggregate dataframe identifying which questions are entirely missing in certain country-waves. I define a small function, `allmiss()`, which counts the number of non-missing values within a country-wave. If the sum of non-missing values is 0 (meaning, all values are missing), the function returns `TRUE`. 

```{r systematically_missing}
#_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
# Function: determine if all observations are missing in cluster

allmiss <- function(var) {
  r <- (sum(!is.na(var)) == 0)
  return(r)
}

#_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
# Create summary dataset showing country-waves where variables are 
# entirely missing

mdsummary <- evs %>%
  group_by(countrywave) %>%
  summarize(
    miss_stflife = allmiss(stflife), 
    miss_women = allmiss(women), 
    miss_age = allmiss(age), 
    miss_edulvl = allmiss(edulvl), 
    miss_eduage = allmiss(eduage)
    )

summary(mdsummary[, 2:ncol(mdsummary)]) 
```

The variable `edulvl` is the only one with systematically missing values. In **half** of the 52 country-waves, respondents were not asked about their highest level of education. If we were to use listwise deletion, thousands of obervations would be lost. 

Fortunately, in all the country-waves, respondents were asked about the age at which they completed their formal education. `eduage` probably gives us a good grasp of the educational attainment of respondents. Let's examine this graphically. 

```{r histogram}
g <- ggplot(data=subset(evs, !is.na(edulvl) & !is.na(eduage)), 
            aes(x = as.numeric(eduage), fill = edulvl))
g <- g + geom_histogram(position="identity", alpha = 0.5, binwidth = 2)
g <- g + labs(x = "Age, completed formal education", y = "Number of observations")
g <- g + scale_fill_discrete(name = "Level of education")
g
```

What do we see? Respondents who completed their formal education at an older age have a higher level of education in general. However, there is substantial overlap between the three categories. If we were to fill in the missing values of `edulvl` on the basis of `eduage` in a single imputation, we would underestimate the uncertainty of our estimates. With multiple imputation, we can fill in the missing data while preserving the uncertainty of the imputations. 

## Generating the MI datasets

Results from analyses with MI data are said to be unbiased if data is ["Missing at random" (MAR)](https://en.wikipedia.org/wiki/Missing_data#Types_of_missing_data), that is, if unobserved variables are uncorrelated with the missing mechanism. The example introduced here is a plausible MAR case. 

Analyzing multiply imputed data involves three steps:

1. _Generate m new datasets with imputed data._ Each dataset contains the same initial, non-missing values, but different imputed values that vary across the mi datasets to reflect the uncertainty of our predictions. 
2. _Fit separate statistical models on each mi dataset._
3. _Pool the results following_ [Rubin's rules](http://www.stat.columbia.edu/~gelman/arm/missing.pdf) [@rubin_multiple_1987; @king_analyzing_2001]

`mice` is a powerful and well-documented R package to perform these operations. It uses chained equations to impute separately each variable with missing values. It works well with continuous, binary, unordered categorical, and ordered categorical data. An excellent resource to learn how to use the package are the [vignettes](https://cran.r-project.org/web/packages/mice/vignettes/resources.html) prepared by Gerko Vink and Stef van Buuren in `mice`'s official documentation.

Let's explore how `mice` would impute the EVS data. To see the default settings without actually imputating anything, we simply have to run the `mice()` function with the number of iterations (`maxit`) set to zero. The `meth` argument indicates which univariate imputation method will be used for each variable with missing values. 

```{r imp_meth_default}
ini <- mice(evs, maxit = 0)
meth <- ini$meth
meth 
```

By default, `mice()` performs predictive mean matching (`pmm`) for numeric variables, logistic regression imputation (`logreg`) for boolean variables and factors with two levels, and polytomous regression imputation (`polyreg`) for unordered factors with more than two levels. We can keep the default settings except for `stflife` and `edulvl` since these variables are ordered. We can estimate proportional odds models (`polr`) instead.

```{r imp_meth_change}
meth[c("stflife", "edulvl")] <- "polr"
meth
```

We can now have a look at the predictors for each equation. 

```{r imp_pred_default}
pred <- ini$pred
pred
```

To fill in the missing values in each incomplete variable, `mice()` will use all remaining variables in the model. This is usually a good strategy since it improves our leverage to predict the missing data. We can however exclude `wave` since we already control for country and country-wave dummies; it does not add substantive information to the predictions. Note that, in the case of systematically-missing data, country-wave dummies for which data is entirely missing will not contribute to the model.

```{r imp_pred_change}
pred[, c("wave")] <- 0
pred
```

We are now ready to generate _m_ MI datasets. A higher number of imputed datasets would make statistical estimates more stable. However, since our number of observations is high, let's limit _m_ to a reasonable number, 5 (the default). We can also set a `seed` to make the results reproducible. 

**Warning: this will take several minutes to compute given the number of observations.**

```{r imp_generate_midata}
imp <- mice(evs, m = 5, meth = meth, pred = pred, seed = 123, print = TRUE)
```

## Fitting separate models and pooling the results

I complete this vignette by performing a multilevel linear model with random effects to predict life satisfication as a function of gender, age, and the level of education. Our data has a hierchical structure: individual-level observations are nested within country-waves, which are themselves clustered within countries. We will therefore fit a three-level model. For simplicity, we assume that `stflife` is a continuous variable with a normal distribution (the 10 point scale is not too far from that). Note also that 13 countries is a rather low number of clusters to perform a multilevel model; keep in mind that this might introduce some bias. 

To perform the multilevel analysis, we will use the `lmer()` function in the `lme4` package [for more information, see @bates_fitting_2015]. We fit a three-level linear model with random intercepts for countries and country-waves within countries using the MI data stored in the object `imp`. 

```{r mi_estimate}
fit <- with(imp, lmer(as.numeric(stflife) ~ women + age + edulvl + (1 | country/countrywave)))
fit
```

Finally, we pool the results. Note that, for the moment, `mice` can only pool the fixed part of the results. 

```{r mi_pool}
pool.fit <- pool(fit)
summary(pool.fit)[, 1:7] # print result and keep relevant columns
```

```{r save_results, echo=FALSE}
results <- summary(pool.fit)
b_edulvl3 <- results["edulvl3", "est"] %>% round(digits = 2)
```

This procedure has allowed us to analyze the entire dataset rather than just the last two EVS waves. The analysis now covers the period from 1981 to 2010 instead of 1999 to 2010. The results show that, all other things being equal, people with a high level of education are more satisfied with their lives by a factor of `r b_edulvl3` on the 10 point scale in comparison with people with a low level of education.  

# Final remarks

Multiple imputation constitutes a great tool to harmonize repeated cross-national surveys. In comparison with listwise deletion, it preserves valuable information and does not introduce bias if data is missing at random. There are however a few points to keep in mind:

* The technique I introduced, with country and country-wave dummies included in the imputation models, has been labelled stratified multiple imputation (or fixed-effect multiple imputation). It can be biased if the relationship among variables varies significantly across countries or country-waves (in most cases, it is still a clear improvement in comparison with listwise deletion). Multiple imputation of clustered data is a field in active development. The objective of this vignette was not to present the bleeding edge of research, but rather to introduce students and researchers to an efficient and relatively simple method to harmonize cross-national surveys. 

* If you are interested in more advanced techniques, such as multilevel imputation with random effect speficications, I list additional references [@grund_multiple_2018; @resche-rigon_multiple_2016]. Note that these techniques are usually much more computationally demanding, are subject to convergence issues, and might not support categorical variables. `miceadds`, an extension of the `mice` package, and the `mitml` package are good solutions if you plan to move forward with multilevel multiple imputation.

* I want to conclude by pointing out that another approach to the problem of systematically-missing data in cross-national surveys could be to fit separate imputation models on each country. This way, the multiple imputation procedure would take into account different relationships between variables within the clusters. This can be done by specifying multiple interaction effects of the form `countryA * variable1 + countryB * variable1 + ...`.

# References